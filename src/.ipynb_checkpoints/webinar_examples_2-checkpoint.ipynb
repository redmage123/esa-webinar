{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e162ecc-7d24-489c-97ee-43c46bc142ec",
   "metadata": {},
   "source": [
    "## Model 1: Convolutional Neural Network (CNN) with Attention Layer\n",
    "\n",
    "This section demonstrates how to build and train a Convolutional Neural Network (CNN) with an attention mechanism. The model is designed for image classification tasks. We will use the Keras library to construct the model, compile it, and train it on a dataset.\n",
    "\n",
    "### Steps:\n",
    "1. **Build the CNN model with an attention layer.**\n",
    "2. **Compile the model with an appropriate optimizer and loss function.**\n",
    "3. **Train the model on a given dataset.**\n",
    "4. **Plot the training accuracy and loss.**\n",
    "5. **Evaluate the model's performance.**\n",
    "6. **Visualize the attention weights on sample images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a03849-a1f9-4677-aca0-ccb043fe6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict,List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b9ef55-d8c1-4e1c-a2a6-04760a7c28ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "647a1a81-5151-400b-9d6a-bdb5877c2e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train data shape: torch.Size([50000, 32, 32, 3])\n",
      "Test data shape: torch.Size([10000, 32, 32, 3])\n",
      "Train labels shape: torch.Size([50000])\n",
      "Test labels shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Define the transformation pipeline\n",
    "transform: transforms.Compose = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std for each channel\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "# trainset and testset are instances of torchvision.datasets.CIFAR10\n",
    "trainset: torchvision.datasets.CIFAR10 = torchvision.datasets.CIFAR10(\n",
    "    root='./data',  # Directory to store the dataset\n",
    "    train=True,     # This is the training set\n",
    "    download=True,  # Download if not present\n",
    "    transform=transform  # Apply the defined transforms\n",
    ")\n",
    "testset: torchvision.datasets.CIFAR10 = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=False,    # This is the test set\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Set batch size for data loading\n",
    "batch_size: int = 64\n",
    "\n",
    "# Create data loaders\n",
    "# DataLoader handles batching, shuffling, and parallel data loading\n",
    "trainloader: DataLoader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,   # Shuffle the training data\n",
    "    num_workers=2   # Number of subprocesses for data loading\n",
    ")\n",
    "testloader: DataLoader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,  # No need to shuffle test data\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Class names for CIFAR-10 dataset (to simulate satellite image classes)\n",
    "class_names: List[str] = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# If you need to access the raw data (similar to the original cell)\n",
    "# Convert uint8 to float and normalize to [0, 1]\n",
    "train_data: torch.Tensor = torch.tensor(trainset.data).float() / 255.0\n",
    "test_data: torch.Tensor = torch.tensor(testset.data).float() / 255.0\n",
    "train_labels: torch.Tensor = torch.tensor(trainset.targets)\n",
    "test_labels: torch.Tensor = torch.tensor(testset.targets)\n",
    "\n",
    "# Move data to GPU if available\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe40e13f-7bf3-4a85-a0b9-212c6566dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images and labels\n",
    "test_images, test_labels = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11978f32-ab38-4366-9da0-2503cbccf6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Neural Network (CNN) model implemented in PyTorch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64)  # Changed from 64 * 4 * 4 to 64 * 8 * 8\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "        x (torch.Tensor): Input tensor of shape (batch_size, 3, 32, 32)\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor of shape (batch_size, 10)\n",
    "        \"\"\"\n",
    "\n",
    "        #x = x.permute(0, 3, 1, 2)\n",
    "        # Apply convolutional layers with ReLU activation and max pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        # print(\"Shape before reshape:\", x.shape)  # Add this line\n",
    "        \n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        # Apply fully connected layers with ReLU activation\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Apply softmax to the output\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def create_cnn_model() -> nn.Module:\n",
    "    \"\"\"\n",
    "    Creates a Convolutional Neural Network (CNN) model.\n",
    "\n",
    "    Returns:\n",
    "    nn.Module: The constructed CNN model.\n",
    "    \"\"\"\n",
    "    return CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705eec8-d31f-4af0-8fe9-737b923d1f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n",
      "Epoch 1/100: Train Loss: 2.0750, Train Acc: 0.3778, Val Loss: 1.9730, Val Acc: 0.4870\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the model instance\n",
    "cnn_model = CNNModel().to('cuda:0')  # Adjust num_classes if needed\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs):\n",
    "    # Set the device (GPU if available, else CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print ('device = ',device)\n",
    "    model = model.to(device)  # Move the model to the selected device\n",
    "    \n",
    "    # Initialize dictionary to store training history\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "            #print (inputs.shape)\n",
    "            #inputs = inputs.permute(0, 3, 1, 2)  # Permute here, before passing to the model\n",
    "            #print ('After permute, shape is ',inputs.shape)\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "           \n",
    "            #inputs = inputs.permute(0, 3, 1, 2)\n",
    "            \n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            \n",
    "            # Accumulate loss and accuracy statistics\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                #inputs = inputs.permute(0, 3, 1, 2)  # Permute here as well\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Accumulate validation loss and accuracy statistics\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Calculate average validation loss and accuracy\n",
    "        val_loss = val_loss / len(test_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Store the results in the history dictionary\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Define the loss function (criterion)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)  # You can adjust the learning rate\n",
    "\n",
    "# Train the model\n",
    "history = train_model(cnn_model, trainloader, testloader, criterion, optimizer, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7dd39c-8648-486b-821a-feccd9a57f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_image(img: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rescale the image to be between 0 and 1.\n",
    "    \"\"\"\n",
    "    img = img.numpy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    img = np.transpose(img, (1, 2, 0))  # Change from (C, H, W) to (H, W, C)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc2d38-9ccb-4246-9481-af33d4b24d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "cnn_model.eval()\n",
    "\n",
    "# Get a batch of test images and labels using the testloader\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "# Move test_images to the same device as the model\n",
    "device = next(cnn_model.parameters()).device\n",
    "test_images = test_images.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "# No need to permute dimensions as the DataLoader already provides the correct format\n",
    "# test_images is already in shape [N, C, H, W]\n",
    "\n",
    "# Get a batch of test images (assuming test_images is a PyTorch tensor)\n",
    "test_batch = test_images[:5]  # Take the first 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7f8ea-319f-437b-a621-75a692ff8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    outputs = cnn_model(test_batch)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    predictions = probabilities.cpu().numpy()  # Convert to numpy array\n",
    "\n",
    "# Now 'predictions' is a numpy array containing the probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd053743-dbdb-4f99-9174-938ff7ef6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(predictions: np.ndarray, test_images: torch.Tensor, test_labels: torch.Tensor, class_names: List[str], num_images=5) -> None:\n",
    "    \"\"\"\n",
    "    Displays the actual and predicted labels for a subset of test images.\n",
    "    \"\"\"\n",
    "    # Ensure tensors are on CPU\n",
    "    test_images = test_images.cpu()\n",
    "    test_labels = test_labels.cpu()\n",
    "    \n",
    "    num_images = min(num_images, len(test_images))\n",
    "    for i in range(num_images):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        # Display the original image with actual label\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(rescale_image(test_images[i]))\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Actual: {class_names[test_labels[i].item()]}')\n",
    "        \n",
    "        # Display the original image with predicted label\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(rescale_image(test_images[i]))\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Predicted: {class_names[np.argmax(predictions[i])]}')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Assume predictions, test_images, test_labels, and class_names are already defined\n",
    "\n",
    "# Call the function\n",
    "display_predictions(predictions, test_images, test_labels, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22833a80-8ec4-46a0-aefd-474671f086c6",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network (GAN)\n",
    "\n",
    "This section demonstrates how to create, compile, train, and generate images using a Generative Adversarial Network (GAN). GANs consist of two neural networks, a generator and a discriminator, that compete against each other to produce realistic images.\n",
    "\n",
    "### Steps:\n",
    "1. **Create the generator and discriminator models.**\n",
    "2. **Compile the models with appropriate optimizers and loss functions.**\n",
    "3. **Train the GAN on a dataset of images obtained from the European Space Agency**\n",
    "4. **Generate and display new images using the trained generator.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e497026-9a5a-4626-ace6-3bd067df0245",
   "metadata": {},
   "source": [
    "# Applications of GANs in Satellite Imagery Processing\n",
    "\n",
    "GANs (Generative Adversarial Networks) can significantly enhance the processing and analysis of satellite imagery in various ways:\n",
    "\n",
    "1. **Super-resolution**\n",
    "   - Enhance the resolution of low-quality satellite images\n",
    "   - Useful for working with older or lower-resolution satellite data\n",
    "\n",
    "2. **Image-to-image translation**\n",
    "   - Transform images between different domains (e.g., daytime to nighttime)\n",
    "   - Convert between different spectral bands\n",
    "\n",
    "3. **Cloud removal**\n",
    "   - Remove cloud cover from images to reveal ground features\n",
    "\n",
    "4. **Data augmentation**\n",
    "   - Generate synthetic satellite imagery to expand training datasets\n",
    "\n",
    "5. **Change detection**\n",
    "   - Compare GAN-generated \"expected\" images with actual imagery to detect changes\n",
    "\n",
    "6. **Filling in missing data**\n",
    "   - Reconstruct missing or corrupted parts of satellite images\n",
    "\n",
    "7. **Multi-temporal analysis**\n",
    "   - Generate time series of satellite imagery for studying changes over time\n",
    "\n",
    "8. **Domain adaptation**\n",
    "   - Adapt imagery from one geographic region to match characteristics of another\n",
    "\n",
    "9. **Sensor fusion**\n",
    "   - Combine data from multiple satellite sensors into composite images\n",
    "\n",
    "10. **Anomaly detection**\n",
    "    - Identify unusual features or patterns in satellite imagery\n",
    "\n",
    "These applications can improve the quality and usability of satellite data, enabling more accurate analysis in fields such as:\n",
    "\n",
    "- Environmental monitoring\n",
    "- Urban planning\n",
    "- Agriculture\n",
    "- Disaster response\n",
    "\n",
    "The specific application of GANs in your project would depend on your particular challenges and goals. For instance:\n",
    "\n",
    "- Use super-resolution for low-quality imagery\n",
    "- Apply cloud removal if cloud cover is a significant issue\n",
    "- Implement change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625b93b4-4bfc-46be-bd66-c0a93d8b8aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import io\n",
    "import random\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Tuple, Optional\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828c5454-6552-479c-bf6a-20524f610e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94b4fa-3cc5-4299-b5dd-5f6a7b239051",
   "metadata": {},
   "source": [
    "In this setup, we're not generating anomalous images. Instead, we're using the existing EuroSAT dataset to create a dataset suitable for anomaly detection. Here's how it works:\n",
    "\n",
    "1. We define certain classes as \"normal\" (e.g., 'Forest', 'AnnualCrop').\n",
    "2. All other classes in the dataset are considered potential \"anomalies\".\n",
    "3. We create a dataset that consists mostly of \"normal\" images, with a small percentage of \"anomalous\" images mixed in.\n",
    "\n",
    "This approach is based on the idea that in a real-world anomaly detection scenario, you typically have mostly normal data with occasional anomalies.\n",
    "\n",
    "Here's a breakdown of what the code is doing:\n",
    "\n",
    "1. It downloads all images from the EuroSAT dataset.\n",
    "2. It separates the images into two categories:\n",
    "   - Normal: Images from the classes specified in `normal_classes`\n",
    "   - Anomaly: Images from all other classes\n",
    "3. It keeps all the \"normal\" images.\n",
    "4. It randomly selects a subset of the \"anomaly\" images to match the specified `anomaly_ratio`.\n",
    "5. It combines these normal and anomaly images to create the final dataset.\n",
    "\n",
    "The resulting dataset can be used to train and evaluate anomaly detection models, including GANs. Here's how you might use it with a GAN:\n",
    "\n",
    "1. Train the GAN only on the normal images (label 0).\n",
    "2. Use the trained GAN to detect anomalies:\n",
    "   - The GAN should be able to reconstruct normal images well.\n",
    "   - It should struggle to reconstruct anomalous images (which it wasn't trained on).\n",
    "   - This difference in reconstruction quality can be used to detect anomalies.\n",
    "\n",
    "We're not generating new anomalous images. Instead, we're using real images from different classes as stand-ins for anomalies. This approach allows us to create a controlled dataset for developing and testing anomaly detection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ecca4e-9f4b-448a-b6d3-e410348d40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATAnomalyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 image_size: int = 64, \n",
    "                 normal_classes: Optional[List[str]] = None, \n",
    "                 anomaly_ratio: float = 0.1, \n",
    "                 root_dir: Optional[str] = None):\n",
    "        self.image_size: int = image_size\n",
    "        self.normal_classes: List[str] = normal_classes if normal_classes else ['AnnualCrop']\n",
    "        self.anomaly_ratio: float = anomaly_ratio\n",
    "        \n",
    "        self.root_dir: str = r\"c:\\Users\\bbrel\\esa_webinar\"\n",
    "        \n",
    "        self.data_dir: str = os.path.join(self.root_dir, 'data')\n",
    "        self.zip_path: str = os.path.join(self.data_dir, 'EuroSAT.zip')\n",
    "        self.extract_path: str = os.path.join(self.data_dir, '2750')\n",
    "\n",
    "        self.transform: transforms.Compose = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "        self.data: List[Tuple[str, int]] = self.download_and_extract_dataset()\n",
    "\n",
    "    def download_and_extract_dataset(self) -> List[Tuple[str, int]]:\n",
    "        if not os.path.exists(self.zip_path):\n",
    "            raise FileNotFoundError(f\"EuroSAT.zip not found at {self.zip_path}. Please ensure the file is in the correct location.\")\n",
    "\n",
    "        if not os.path.exists(self.extract_path):\n",
    "            print(f\"Extracting dataset to {self.extract_path}\")\n",
    "            with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.data_dir)\n",
    "\n",
    "        data: List[Tuple[str, int]] = []\n",
    "        all_classes: List[str] = [d for d in os.listdir(self.extract_path) if os.path.isdir(os.path.join(self.extract_path, d))]\n",
    "        \n",
    "        if not all_classes:\n",
    "            raise FileNotFoundError(f\"No class directories found in {self.extract_path}. Please check the dataset structure.\")\n",
    "\n",
    "        anomaly_classes: List[str] = [c for c in all_classes if c not in self.normal_classes]\n",
    "\n",
    "        for class_name in all_classes:\n",
    "            class_path: str = os.path.join(self.extract_path, class_name)\n",
    "            is_normal: bool = class_name in self.normal_classes\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path: str = os.path.join(class_path, img_name)\n",
    "                if is_normal or (not is_normal and random.random() < self.anomaly_ratio):\n",
    "                    data.append((img_path, 0 if is_normal else 1))\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        img_path, label = self.data[idx]\n",
    "        image: Image.Image = Image.open(img_path).convert('RGB')\n",
    "        image: torch.Tensor = self.transform(image)\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fc27ee-b434-42cf-a41f-c2b11e2b1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eurosat_anomaly_dataset(\n",
    "    batch_size: int = 32, \n",
    "    image_size: int = 64, \n",
    "    normal_classes: Optional[List[str]] = None, \n",
    "    anomaly_ratio: float = 0.1, \n",
    "    num_workers: int = 4\n",
    ") -> Tuple[DataLoader, EuroSATAnomalyDataset]:\n",
    "    dataset: EuroSATAnomalyDataset = EuroSATAnomalyDataset(image_size, normal_classes, anomaly_ratio)\n",
    "    dataloader: DataLoader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    return dataloader, dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cc61ed-efca-4b82-b0e7-a81fcd7a3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "config = {\n",
    "    'latent_dim': 100,\n",
    "    'lr': 0.0002,\n",
    "    'beta1': 0.5,\n",
    "    'beta2': 0.999,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'image_size': 64,\n",
    "    'print_every': 100,\n",
    "    'save_interval': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54264812-7426-4170-9d41-c56780091180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5352\n",
      "Normal classes: ['AnnualCrop']\n",
      "Anomaly ratio: 0.1\n",
      "Normal samples: 3000\n",
      "Anomaly samples: 2352\n"
     ]
    }
   ],
   "source": [
    "normal_classes = None  \n",
    "anomaly_ratio = 0.1  \n",
    "dataloader, dataset = load_eurosat_anomaly_dataset(config['batch_size'], config['image_size'], normal_classes, anomaly_ratio)\n",
    "\n",
    "print(f'Dataloader length: {len(dataloader)}')\n",
    "print(f'Dataloader batch size: {dataloader.batch_size}')\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Normal classes: {dataset.normal_classes}\")\n",
    "print(f\"Anomaly ratio: {dataset.anomaly_ratio}\")\n",
    "\n",
    "# Check the balance of normal and anomaly samples\n",
    "normal_count = sum(1 for _, label in dataset if label == 0)\n",
    "anomaly_count = sum(1 for _, label in dataset if label == 1)\n",
    "print(f\"Normal samples: {normal_count}\")\n",
    "print(f\"Anomaly samples: {anomaly_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e05d80e-7ba3-4f80-8427-5edaa9a063fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Generator model for a Generative Adversarial Network (GAN).\n",
    "\n",
    "\n",
    "    This Generator takes a random noise vector of size 100 and transforms it \n",
    "    into a 64x64 RGB image. The architecture consists of several transposed \n",
    "    convolutional layers with increasing sizes, followed by batch normalization \n",
    "    and ReLU activation. The final layer uses a Tanh activation to produce \n",
    "    pixel values in the range [-1, 1].\n",
    "\n",
    "    The network structure is as follows:\n",
    "    1. Input: 100-dimensional noise vector\n",
    "    2. Transposed Conv2d: 512 channels, 4x4\n",
    "    3. Transposed Conv2d: 256 channels, 8x8\n",
    "    4. Transposed Conv2d: 128 channels, 16x16\n",
    "    5. Transposed Conv2d: 64 channels, 32x32\n",
    "    6. Output layer: 3 channels, 64x64 with tanh activation\n",
    "   The output is a 64x64x3 image.\n",
    "   \"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=100, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "         \n",
    "        \"\"\"\n",
    "        Forward pass of the generator.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, latent_dim)\n",
    "        Returns:\n",
    "            torch.Tensor: Generated images of shape (batch_size, 3, 64, 64)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Reshape the input noise vector to (batch_size, latent_dim, 1, 1) and\n",
    "        # pass it through the generator model. This transformation allows the\n",
    "        # first transposed convolution to interpret each latent vector as a 1x1 \"image\"\n",
    "        # with latent_dim channels, which it then upscales to the final 64x64 RGB image.\n",
    "        \n",
    "        img = self.model(x.view(x.size(0), self.latent_dim, 1, 1))\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ee7ce6-4da2-43f1-ae56-199d5c812ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator() -> nn.Module:\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds and returns an instance of the Generator model.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: An instance of the Generator model.\n",
    "    \"\"\"\n",
    "    return Generator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09503ff3-a580-4d5d-8298-30c57bfb8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Discriminator model for a Generative Adversarial Network (GAN).\n",
    "\n",
    "    This Discriminator takes a 64x64 RGB image and classifies it as real \n",
    "    or fake. The architecture consists of several fully connected layers with \n",
    "    convolutional layers with decreasing sizes, using LeakyReLU activations. \n",
    "    The final layer uses a Sigmoid activation to produce a probability output.\n",
    "\n",
    "\n",
    "    The network structure is as follows:\n",
    "    1. Input: 64x64x3 image\n",
    "    2. Conv2d: 64 channels, 4x4 kernel, stride 2, padding 1\n",
    "    3. Conv2d: 128 channels, 4x4 kernel, stride 2, padding 1\n",
    "    4. Conv2d: 256 channels, 4x4 kernel, stride 2, padding 1\n",
    "    5. Conv2d: 512 channels, 4x4 kernel, stride 2, padding 1\n",
    "    6. Conv2d: 1 channel, 4x4 kernel, stride 1, padding 0\n",
    "    7. Sigmoid activation\n",
    "\n",
    "    Attributes:\n",
    "        model (nn.Sequential): The sequential container of layers.\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Defines the computation performed at every call.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int = 3) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "           nn.Conv2d(channels, 64, 4, 2, 1, bias=False),\n",
    "           nn.LeakyReLU(0.2, inplace=True),\n",
    "           nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "           nn.BatchNorm2d(128),\n",
    "           nn.LeakyReLU(0.2, inplace=True),\n",
    "           nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "           nn.BatchNorm2d(256),\n",
    "           nn.LeakyReLU(0.2, inplace=True),\n",
    "           nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "           nn.BatchNorm2d(512),\n",
    "           nn.LeakyReLU(0.2, inplace=True),\n",
    "           nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the discriminator.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 3, 64, 64)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Probability of input being real, shape (batch_size, 1, 1, 1)\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef01d5c4-42c4-4975-acf4-2120838a66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator() -> nn.Module:\n",
    "    \"\"\"\n",
    "    Builds and returns an instance of the Discriminator model.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: An instance of the Discriminator model.\n",
    "    \"\"\"\n",
    "    return Discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6107c4-bde6-411f-a6ab-7ee61412cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorTrainer:\n",
    "\n",
    "    \"\"\"\n",
    "    A class for training a Generative Adversarial Network (GAN) for anomaly detection.\n",
    "\n",
    "    This class implements the training process for a GAN, specifically tailored for\n",
    "    anomaly detection tasks. It trains a generator to produce realistic normal samples\n",
    "    and a discriminator to distinguish between real and generated samples. After training,\n",
    "    the GAN can be used to detect anomalies by comparing input images to generated ones.\n",
    "\n",
    "    The class handles the entire training process, including:\n",
    "    - Initializing and managing the generator and discriminator models\n",
    "    - Setting up optimizers and loss functions\n",
    "    - Implementing the GAN training loop\n",
    "    - Saving generated images and trained models\n",
    "    - Providing a method for anomaly detection using the trained models\n",
    "\n",
    "    Attributes:\n",
    "        generator (nn.Module): The generator model of the GAN.\n",
    "        discriminator (nn.Module): The discriminator model of the GAN.\n",
    "        config (dict): A dictionary containing all hyperparameters and configuration settings.\n",
    "        device (torch.device): The device (CPU or GPU) on which to perform computations.\n",
    "        criterion (nn.Module): The loss function (typically BCELoss for GANs).\n",
    "        optimizer_G (torch.optim.Optimizer): The optimizer for the generator.\n",
    "        optimizer_D (torch.optim.Optimizer): The optimizer for the discriminator.\n",
    "\n",
    "    The config dictionary should contain the following keys:\n",
    "    - 'latent_dim': Dimension of the latent space for the generator\n",
    "    - 'lr': Learning rate for the optimizers\n",
    "    - 'beta1', 'beta2': Beta parameters for the Adam optimizer\n",
    "    - 'num_epochs': Number of epochs to train\n",
    "    - 'batch_size': Batch size for training\n",
    "    - 'print_every': How often to print training progress\n",
    "    - 'save_interval': How often to save generated images\n",
    "\n",
    "    Methods:\n",
    "        train_step(real_images): Performs a single training step for both generator and discriminator.\n",
    "        train(dataloader): Runs the full training loop over the entire dataset.\n",
    "        save_images(epoch): Saves a batch of generated images.\n",
    "        save_models(): Saves the trained generator and discriminator models.\n",
    "        detect_anomalies(images, threshold): Uses the trained GAN to detect anomalies in input images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, generator: nn.Module, discriminator: nn.Module, config: dict):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initializes the DiscriminatorTrainer with given models and configuration.\n",
    "\n",
    "        Args:\n",
    "            generator (nn.Module): The generator model.\n",
    "            discriminator (nn.Module): The discriminator model.\n",
    "            config (dict): Configuration dictionary containing hyperparameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.config = config\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Move models to the appropriate device\n",
    "        self.generator.to(self.device)\n",
    "        self.discriminator.to(self.device)\n",
    "        \n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optimizer_G = optim.Adam(self.generator.parameters(), \n",
    "                                      lr=config['lr'], \n",
    "                                      betas=(config['beta1'], config['beta2']))\n",
    "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), \n",
    "                                      lr=config['lr'], \n",
    "                                      betas=(config['beta1'], config['beta2']))\n",
    "\n",
    "    def train_step(self, real_images: torch.Tensor) -> Tuple[float, float]:\n",
    "\n",
    "        \"\"\"\n",
    "        Performs a single training step for both the generator and discriminator.\n",
    "\n",
    "        Args:\n",
    "            real_images (torch.Tensor): A batch of real images to train on.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the discriminator loss and generator loss for this step.\n",
    "        \"\"\"\n",
    "        print(\"Starting train step\")\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(self.device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        self.optimizer_D.zero_grad()\n",
    "        \n",
    "        # Real images\n",
    "        # Create a tensor of ones with shape (batch_size, 1, 1, 1)\n",
    "        # This represents the \"real\" labels for the discriminator\n",
    "        # The shape (batch_size, 1, 1, 1) matches the output of the discriminator\n",
    "        # We use ones because we want the discriminator to identify these as real image\n",
    "        real_labels = torch.ones(batch_size, 1, 1, 1).to(self.device)\n",
    "        \n",
    "\n",
    "        # Pass the real images through the discriminator\n",
    "        # The discriminator attempts to classify these images as real or fake\n",
    "        # output will have shape (batch_size, 1, 1, 1), where each value represents\n",
    "        # the discriminator's confidence that the corresponding image is real \n",
    "        output = self.discriminator(real_images)\n",
    "        \n",
    "        # Calculate the loss for the real images\n",
    "        # We use Binary Cross Entropy (BCE) loss, comparing the discriminator's output\n",
    "        # to the real_labels (all ones)\n",
    "        # This loss will be low if the discriminator correctly identifies the real images,\n",
    "        # and high if it misclassifies them as fake\n",
    "        d_loss_real = self.criterion(output, real_labels)\n",
    "        \n",
    "        # Fake images\n",
    "        # Generate random noise as input for the generator\n",
    "        # The shape is (batch_size, latent_dim), where latent_dim is defined in the config\n",
    "        # This noise serves as the seed for generating fake images\n",
    "        z = torch.randn(batch_size, self.config['latent_dim']).to(self.device)\n",
    "\n",
    "        # Use the generator to create fake images from the random noise\n",
    "        # fake_images will have the same shape as real images in the dataset\n",
    "        fake_images = self.generator(z)\n",
    "        print(\"Generated fake images\")\n",
    "        # Create a tensor of zeros with shape (batch_size, 1, 1, 1)\n",
    "        # This represents the \"fake\" labels for the discriminator\n",
    "        # We use zeros because we want the discriminator to identify these as fake images\n",
    "        fake_labels = torch.zeros(batch_size, 1, 1, 1).to(self.device)\n",
    "\n",
    "        # Pass the fake images through the discriminator\n",
    "        # We use detach() to prevent gradients from flowing back to the generator\n",
    "        # This is because we're currently training the discriminator, not the generator \n",
    "        output = self.discriminator(fake_images.detach())\n",
    "\n",
    "        # Calculate the loss for the fake images\n",
    "        # We use Binary Cross Entropy (BCE) loss, comparing the discriminator's output\n",
    "        # to the fake_labels (all zeros)\n",
    "        # This loss will be low if the discriminator correctly identifies the fake images,\n",
    "        # and high if it misclassifies them as real \n",
    "        d_loss_fake = self.criterion(output, fake_labels)\n",
    "        print(\"Computed discriminator loss\")\n",
    "        # Combine the losses from real and fake images\n",
    "        # This gives us the total loss for the discriminator\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # Compute gradients of the total loss with respect to the discriminator's parameters\n",
    "        # This prepares for the backward pass in neural network training \n",
    "        d_loss.backward()\n",
    "         \n",
    "        # Update the discriminator's parameters using the computed gradients\n",
    "        # This is the actual learning step for the discriminator\n",
    "        self.optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        # Reset the gradients for the generator's parameters to zero\n",
    "        # This is necessary before computing new gradients \n",
    "        self.optimizer_G.zero_grad()\n",
    "\n",
    "        # Pass the fake images through the discriminator\n",
    "        # Note: We're using the same fake images generated earlier, but this time we don't detach them\n",
    "        # because we want to compute gradients with respect to the generator's parameters\n",
    "        output = self.discriminator(fake_images)\n",
    "\n",
    "        # Calculate the generator's loss\n",
    "        # We use the same criterion (BCE loss) as before, but now we compare the output to real_labels\n",
    "        # This trains the generator to produce images that the discriminator will classify as real\n",
    "        g_loss = self.criterion(output, real_labels)\n",
    "        print(\"Computed generator loss\")\n",
    "\n",
    "        # Compute gradients of the loss with respect to the generator's parameters \n",
    "        g_loss.backward()\n",
    "         \n",
    "        # Update the generator's parameters using the computed gradients\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        print(\"Finished train step\")\n",
    "\n",
    "        return d_loss.item(), g_loss.item()\n",
    "\n",
    "    def train(self, dataloader: torch.utils.data.DataLoader) -> None:\n",
    "        \"\"\"\n",
    "        Runs the full training loop over the entire dataset for the specified number of epochs.\n",
    "\n",
    "        Args:\n",
    "            dataloader (torch.utils.data.DataLoader): The DataLoader containing the training data.\n",
    "        \"\"\"\n",
    "\n",
    "        print('Testing dataloader')\n",
    "        for i, (real_images, labels) in enumerate(dataloader):\n",
    "            print(f'Loaded batch {i+1}, shape: {real_images.shape}')\n",
    "            if i == 2:  # Just print the first 3 batches\n",
    "                break\n",
    "        print('Dataloader test complete')\n",
    "        total_batches = len(dataloader) * self.config['num_epochs']\n",
    "        print ('total_batches = ',total_batches)\n",
    "        print ('In train')\n",
    "        with tqdm(total=total_batches, desc=\"Training Progress\") as pbar:\n",
    "            print ('Starting for loop')\n",
    "            for epoch in range(self.config['num_epochs']):\n",
    "                print(f'Starting epoch {epoch+1}')\n",
    "                for i, (real_images, labels) in enumerate(dataloader):\n",
    "                    print(f'Batch {i+1}: Loading data')\n",
    "                    print(f'Batch {i+1}: Real images shape: {real_images.shape}')\n",
    "                    print(f'Batch {i+1}: Calling train step')\n",
    "                    d_loss, g_loss = self.train_step(real_images)\n",
    "\n",
    "                    # Update tqdm progress bar\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix({\n",
    "                        'Epoch': f\"{epoch+1}/{self.config['num_epochs']}\",\n",
    "                        'Batch': f\"{i+1}/{len(dataloader)}\",\n",
    "                        'D_loss': f\"{d_loss:.4f}\",\n",
    "                        'G_loss': f\"{g_loss:.4f}\"\n",
    "                    })\n",
    "\n",
    "                # Save generated images\n",
    "                if (epoch + 1) % self.config['save_interval'] == 0:\n",
    "                    self.save_images(epoch)\n",
    "                    pbar.write(f\"Saved images for epoch {epoch+1}\")\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        self.save_models()\n",
    "\n",
    "    def save_images(self, epoch: int) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Saves a batch of generated images.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number, used in the filename of the saved image.\n",
    "        \"\"\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake = self.generator(torch.randn(64, self.config['latent_dim'], 1, 1, device=self.device))\n",
    "            save_image(fake.detach(), f\"fake_images_epoch_{epoch+1}.png\", normalize=True)\n",
    "\n",
    "    def save_models(self) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Saves the trained generator and discriminator models to disk.\n",
    "        \"\"\"\n",
    "        \n",
    "        torch.save(self.generator.state_dict(), \"generator.pth\")\n",
    "        torch.save(self.discriminator.state_dict(), \"discriminator.pth\")\n",
    "\n",
    "    def detect_anomalies(self, images: torch.Tensor, threshold: float) -> torch.Tensor:\n",
    "\n",
    "        \"\"\"\n",
    "        Uses the trained GAN to detect anomalies in input images.\n",
    "\n",
    "        Args:\n",
    "            images (torch.Tensor): The input images to check for anomalies.\n",
    "            threshold (float): The threshold value for determining anomalies.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A boolean tensor indicating whether each input image is an anomaly.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.generator.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        # Disable gradient computation to save memory and speed up calculations\n",
    "        # This is appropriate since we're not training, just doing inference\n",
    "        with torch.no_grad():\n",
    "\n",
    "        # Generate random noise as input for the generator\n",
    "        # The shape matches the batch size of input images and the latent dimension from config\n",
    "        # Adding two extra dimensions (1, 1) at the end to match potential generator input requirements\n",
    "            z = torch.randn(images.size(0), self.config['latent_dim'], 1, 1).to(self.device)\n",
    "            \n",
    "            # Use the generator to create reconstructed images from the random noise\n",
    "            # These reconstructed images should ideally be similar to normal, non-anomalous images\n",
    "            reconstructed = self.generator(z)\n",
    "            \n",
    "            # Calculate the mean squared error between original images and reconstructed images\n",
    "            # This error is computed for each image separately, across all channels and pixels\n",
    "            # The result is a 1D tensor with one value per image in the batch\n",
    "            reconstruction_error = torch.mean((images - reconstructed) ** 2, dim=(1, 2, 3))\n",
    "\n",
    "            # Use the reconstruction error as the anomaly score\n",
    "            # Higher reconstruction error suggests higher likelihood of being an anomaly\n",
    "            anomaly_scores = reconstruction_error\n",
    "\n",
    "            # Compare anomaly scores to the threshold\n",
    "            # Returns a boolean tensor: True for anomalies (score > threshold), False otherwise\n",
    "            return anomaly_scores > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f78c8123-9b6e-4d69-941e-38acb96ee9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator and discriminator\n",
    "generator = Generator(config['latent_dim']).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = DiscriminatorTrainer(generator, discriminator, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4eb791a-f808-452a-ab54-b783b9de17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator device: cuda:0\n",
      "Discriminator device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Generator device:\", next(trainer.generator.parameters()).device)\n",
    "print(\"Discriminator device:\", next(trainer.discriminator.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c14462-3f3f-4725-b33e-286aa434811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CUDA operation\n",
      "CUDA operation completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing CUDA operation\")\n",
    "test_tensor = torch.rand(100, 100).cuda()\n",
    "result = torch.matmul(test_tensor, test_tensor)\n",
    "print(\"CUDA operation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6bcaf1-c9f3-4c05-b272-b4979c58531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataloader\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "trainer.train(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd70436-2dae-4f14-adaa-5b53d589a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTester:\n",
    "    \n",
    "    \"\"\"\n",
    "    A class for testing a trained Generative Adversarial Network (GAN) for anomaly detection.\n",
    "\n",
    "    This class provides methods to load a trained GAN model and use it to detect anomalies\n",
    "    in a test dataset.\n",
    "\n",
    "    Attributes:\n",
    "        generator (nn.Module): The trained generator model.\n",
    "        discriminator (nn.Module): The trained discriminator model.\n",
    "        device (torch.device): The device (CPU or GPU) on which to perform computations.\n",
    "        config (dict): Configuration dictionary containing model and testing parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, generator: nn.Module, discriminator: nn.Module, config: dict):\n",
    "        \"\"\"\n",
    "        Initializes the GANTester with trained models and configuration.\n",
    "\n",
    "        Args:\n",
    "            generator (nn.Module): The trained generator model.\n",
    "            discriminator (nn.Module): The trained discriminator model.\n",
    "            config (dict): Configuration dictionary containing model and testing parameters.\n",
    "        \"\"\"\n",
    "        # Store the generator and discriminator models\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.config = config\n",
    "\n",
    "        # Determine the device (GPU if available, otherwise CPU)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Move models to the appropriate device\n",
    "        self.generator.to(self.device)\n",
    "        self.discriminator.to(self.device)\n",
    "\n",
    "        # Set models to evaluation mode\n",
    "        # This is crucial as it affects certain layers like BatchNorm and Dropout\n",
    "        self.generator.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "    def load_test_data(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Loads and prepares the test dataset.\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: A DataLoader containing the test dataset.\n",
    "        \"\"\"\n",
    "        # Define the image transformations\n",
    "        # These transformations ensure that all images are of the same size and format\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(self.config['image_size']),  # Resize image to a standard size\n",
    "            transforms.CenterCrop(self.config['image_size']),  # Crop the center part of the image\n",
    "            transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize pixel values\n",
    "        ])\n",
    "\n",
    "        # Load the test dataset from the specified path\n",
    "        test_dataset = datasets.ImageFolder(root=self.config['test_data_path'], transform=transform)\n",
    "\n",
    "        # Create a DataLoader for efficient batching and parallel processing\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.config['batch_size'], shuffle=False)\n",
    "        \n",
    "        return test_loader\n",
    "\n",
    "    def detect_anomalies(self, images: torch.Tensor, threshold: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Detects anomalies in the input images using the trained GAN.\n",
    "\n",
    "        Args:\n",
    "            images (torch.Tensor): Batch of input images to check for anomalies.\n",
    "            threshold (float): Threshold value for anomaly detection.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A boolean tensor indicating anomalies (True) and normal samples (False).\n",
    "        \"\"\"\n",
    "        # Disable gradient computation to save memory and speed up calculations\n",
    "        with torch.no_grad():\n",
    "            # Generate random noise as input for the generator\n",
    "            # The shape matches the batch size of input images and the latent dimension from config\n",
    "            z = torch.randn(images.size(0), self.config['latent_dim'], 1, 1).to(self.device)\n",
    "\n",
    "            # Use the generator to create reconstructed images from the random noise\n",
    "            reconstructed = self.generator(z)\n",
    "\n",
    "            # Calculate the mean squared error between original images and reconstructed images\n",
    "            # This error is computed for each image separately, across all channels and pixels\n",
    "            reconstruction_error = torch.mean((images - reconstructed) ** 2, dim=(1, 2, 3))\n",
    "\n",
    "            # Use the reconstruction error as the anomaly score\n",
    "            anomaly_scores = reconstruction_error\n",
    "\n",
    "            # Compare anomaly scores to the threshold\n",
    "            # Returns a boolean tensor: True for anomalies (score > threshold), False otherwise\n",
    "            return anomaly_scores > threshold\n",
    "\n",
    "    def evaluate(self, dataloader: DataLoader, threshold: float) -> Tuple[List[bool], List[int]]:\n",
    "        \"\"\"\n",
    "        Evaluates the anomaly detection performance on the entire test dataset.\n",
    "\n",
    "        Args:\n",
    "            dataloader (DataLoader): DataLoader containing the test dataset.\n",
    "            threshold (float): Threshold value for anomaly detection.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[bool], List[int]]: A tuple containing lists of anomaly detection results and true labels.\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Iterate through all batches in the dataloader\n",
    "        for images, labels in dataloader:\n",
    "            # Move images to the same device as the models\n",
    "            images = images.to(self.device)\n",
    "\n",
    "            # Perform anomaly detection on the current batch\n",
    "            results = self.detect_anomalies(images, threshold)\n",
    "            \n",
    "            # Collect results and labels\n",
    "            # Convert tensors to Python lists for easier post-processing\n",
    "            all_results.extend(results.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "        return all_results, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c118e-3935-4c05-b6af-824f0424ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GANTester\n",
    "tester: GANTester = GANTester(generator, discriminator, config)\n",
    "\n",
    "# Load the test data\n",
    "test_loader: DataLoader = tester.load_test_data()\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold: float = 0.5  # Adjust this value based on your specific needs\n",
    "\n",
    "# Evaluate the model\n",
    "results: List[bool]\n",
    "labels: List[int]\n",
    "results, labels = tester.evaluate(test_loader, threshold)\n",
    "\n",
    "# Print basic results\n",
    "print(f\"Total samples tested: {len(results)}\")\n",
    "print(f\"Anomalies detected: {sum(results)}\")\n",
    "print(f\"Actual anomalies: {sum(labels)}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy: float = sum(r == l for r, l in zip(results, labels)) / len(results)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb1876-2feb-41ba-9b0d-6c8b3f7ca2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_images_with_predictions(\n",
    "    images: torch.Tensor, \n",
    "    reconstructed: torch.Tensor, \n",
    "    predictions: List[bool], \n",
    "    actual: List[int], \n",
    "    num_images: int = 20\n",
    ") -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot original images, their reconstructions, and highlight anomalies.\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Original test images.\n",
    "        reconstructed (torch.Tensor): Reconstructed images from the GAN.\n",
    "        predictions (List[bool]): List of anomaly predictions (True for anomaly).\n",
    "        actual (List[int]): List of actual labels (1 for anomaly, 0 for normal).\n",
    "        num_images (int, optional): Number of images to display. Defaults to 20.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure we don't try to display more images than we have\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    # Randomly select indices for the images we'll display\n",
    "    indices = np.random.choice(len(images), num_images, replace=False)\n",
    "    \n",
    "    # Extract the selected images and their corresponding data\n",
    "    orig_images = images[indices].cpu()\n",
    "    recon_images = reconstructed[indices].cpu()\n",
    "    pred_anomalies = [predictions[i] for i in indices]\n",
    "    actual_anomalies = [actual[i] for i in indices]\n",
    "\n",
    "    # Create a figure with two rows: original images on top, reconstructions on bottom\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(num_images*2, 4))\n",
    "\n",
    "    # Define color scheme for different prediction outcomes\n",
    "    color_scheme = {\n",
    "        (True, True): 'lime',    # True Positive: correctly identified anomaly\n",
    "        (True, False): 'red',    # False Positive: normal sample incorrectly identified as anomaly\n",
    "        (False, True): 'yellow', # False Negative: missed anomaly\n",
    "        (False, False): 'none'   # True Negative: correctly identified normal sample\n",
    "    }\n",
    "\n",
    "    # Plot original and reconstructed images\n",
    "    for i in range(num_images):\n",
    "        for row, img in enumerate([orig_images, recon_images]):\n",
    "            ax = axes[row, i]\n",
    "            \n",
    "            # Display the image\n",
    "            ax.imshow(img[i].permute(1, 2, 0).detach().numpy() * 0.5 + 0.5)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Set the border color based on prediction and actual label\n",
    "            border_color = color_scheme[(pred_anomalies[i], actual_anomalies[i])]\n",
    "            ax.set_facecolor(border_color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037a543-1dc9-4bd5-9a8d-e19cf2b951dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate reconstructed images using the GAN\n",
    "def generate_reconstructions(\n",
    "    generator: torch.nn.Module, \n",
    "    num_samples: int, \n",
    "    latent_dim: int, \n",
    "    device: torch.device\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate reconstructed images using the GAN's generator.\n",
    "\n",
    "    Args:\n",
    "        generator (torch.nn.Module): The trained generator model.\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        latent_dim (int): Dimension of the latent space.\n",
    "        device (torch.device): Device to perform the computation on.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The generated (reconstructed) images.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        # Generate random noise as input for the generator\n",
    "        z = torch.randn(num_samples, latent_dim, 1, 1).to(device)\n",
    "        \n",
    "        # Use the generator to create reconstructed images\n",
    "        reconstructed = generator(z)\n",
    "        \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e91d52-57dc-4c65-8fe0-ed7a4a5aa699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reconstructed images\n",
    "reconstructed = generate_reconstructions(\n",
    "    tester.generator, \n",
    "    len(test_loader.dataset), \n",
    "    config['latent_dim'], \n",
    "    tester.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae436142-e901-44f9-a31c-58dee29f9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get a batch of original images\n",
    "original_images, _ = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83766a8f-f0db-4a07-8eb6-c4f31bfffa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have the same number of original and reconstructed images\n",
    "num_images = min(len(original_images), len(reconstructed))\n",
    "original_images = original_images[:num_images]\n",
    "reconstructed = reconstructed[:num_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dd481-610f-4fff-99f4-303235221ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "show_images_with_predictions(original_images, reconstructed, results[:num_images], labels[:num_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee6815b-4309-4d1c-801c-fa334c97784a",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)\n",
    "\n",
    "This section demonstrates how to create, compile, train, and generate images using a Variational Autoencoder (VAE). VAEs are generative models that learn to encode input data into a latent space and decode from the latent space to generate new data.\n",
    "\n",
    "### Steps:\n",
    "1. **Create the encoder and decoder models.**\n",
    "2. **Define the VAE by combining the encoder and decoder.**\n",
    "3. **Compile the VAE with an appropriate loss function.**\n",
    "4. **Train the VAE on a dataset of images.**\n",
    "5. **Generate and display new images using the trained decoder.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
